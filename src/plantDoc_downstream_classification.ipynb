{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581a072f-8b4a-4734-abd5-64809643a724",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)  # If using multiple GPUs\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "##################################\n",
    "# 1. Data Augmentations & Loaders\n",
    "##################################\n",
    "image_size = 384\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((image_size, image_size)),\n",
    "    transforms.RandomApply([\n",
    "       transforms.RandomRotation(15),\n",
    "       transforms.RandomHorizontalFlip(),\n",
    "       transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3, hue=0.1),\n",
    "       transforms.RandomResizedCrop(image_size, scale=(0.8, 1.0))\n",
    "    ], p=0.8),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((image_size, image_size)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Paths to your PlantDoc dataset\n",
    "train_dir = '../PlantDoc-Dataset/train'\n",
    "test_dir = '../PlantDoc-Dataset/test'\n",
    "\n",
    "train_dataset = datasets.ImageFolder(root=train_dir, transform=train_transform)\n",
    "test_dataset  = datasets.ImageFolder(root=test_dir,  transform=test_transform)\n",
    "\n",
    "num_classes = len(train_dataset.classes)\n",
    "class_names = train_dataset.classes\n",
    "print(\"Number of classes:\", num_classes)\n",
    "print(\"Classes:\", class_names)\n",
    "\n",
    "batch_size = 16\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "\n",
    "print(f\"Dataset Loaded! {num_classes} classes found.\")\n",
    "print(\"Number of images in train_loader:\", len(train_loader.dataset))\n",
    "print(\"Number of images in test_loader:\", len(test_loader.dataset))\n",
    "\n",
    "##################################\n",
    "# 2. Define the Model Architecture\n",
    "##################################\n",
    "class MLPClassifier(nn.Module):\n",
    "    def __init__(self, in_features, num_classes):\n",
    "        super(MLPClassifier, self).__init__()\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(in_features, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.classifier(x)\n",
    "\n",
    "def build_model():\n",
    "    model = models.resnet101(weights=None)\n",
    "    model.fc = MLPClassifier(in_features=2048, num_classes=num_classes)\n",
    "    return model\n",
    "\n",
    "##################################\n",
    "# 3. Setup Loss, Optimizer, and Scheduler\n",
    "##################################\n",
    "def setup_training(model, lr=1e-5):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=5e-5)\n",
    "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10)\n",
    "    return criterion, optimizer, scheduler\n",
    "\n",
    "##################################\n",
    "# 4. Fine-Tuning and Evaluation\n",
    "##################################\n",
    "def fine_tune_and_evaluate(checkpoint_path, run_idx=1, num_finetune_epochs=60):\n",
    "    \"\"\"\n",
    "    run_idx is used to generate a unique filename when saving/loading best model.\n",
    "    \"\"\"\n",
    "    print(f\"\\n=== Starting Fine-Tuning for Checkpoint: {checkpoint_path}, Run {run_idx} ===\")\n",
    "    \n",
    "    # Build model and load SSL pre-trained weights from the given checkpoint.\n",
    "    model = build_model()\n",
    "    pretrained_weights = torch.load(checkpoint_path, map_location=device)\n",
    "    model.load_state_dict(pretrained_weights)\n",
    "    print(\"Loaded SSL pre-trained weights successfully.\")\n",
    "    model = model.to(device)\n",
    "    \n",
    "    criterion, optimizer, scheduler = setup_training(model, lr=1e-5)\n",
    "    best_acc = 0.0\n",
    "    \n",
    "    # The unique filename for saving/loading the best model in this run\n",
    "    best_model_filename = f\"plantdoc_best_finetuned_{checkpoint_path}{run_idx}.pth\"\n",
    "    \n",
    "    # Fine-Tuning Loop\n",
    "    for epoch in range(num_finetune_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            correct += preds.eq(labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "        train_loss = running_loss / total\n",
    "        train_acc = correct / total\n",
    "\n",
    "        # Validation Loop\n",
    "        model.eval()\n",
    "        val_running_loss = 0.0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in test_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_running_loss += loss.item() * images.size(0)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                val_correct += preds.eq(labels).sum().item()\n",
    "                val_total += labels.size(0)\n",
    "\n",
    "        val_loss = val_running_loss / val_total\n",
    "        val_acc = val_correct / val_total\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "        print(f\"Epoch [{epoch+1}/{num_finetune_epochs}] - \"\n",
    "              f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc*100:.2f}% | \"\n",
    "              f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc*100:.2f}%\")\n",
    "\n",
    "        # Save best model if improved\n",
    "        if val_acc > best_acc:\n",
    "            best_acc = val_acc\n",
    "            torch.save(model.state_dict(), best_model_filename)\n",
    "            print(f\"Saved Best Model!\")\n",
    "    \n",
    "    print(\"Fine-Tuning Complete for this run!\\n\")\n",
    "\n",
    "    # =======================\n",
    "    # Final Evaluation Phase\n",
    "    # =======================\n",
    "    # Load the best model from this run\n",
    "    model.load_state_dict(torch.load(best_model_filename))\n",
    "    model.eval()\n",
    "    \n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "    \n",
    "    all_labels = np.array(all_labels)\n",
    "    all_preds = np.array(all_preds)\n",
    "    \n",
    "    # Overall metrics\n",
    "    accuracy = (all_preds == all_labels).mean()\n",
    "    macro_precision = precision_score(all_labels, all_preds, average='macro')\n",
    "    macro_recall    = recall_score(all_labels, all_preds, average='macro')\n",
    "    macro_f1        = f1_score(all_labels, all_preds, average='macro')\n",
    "    \n",
    "    print(f\"=== Final Evaluation for {checkpoint_path}, Run {run_idx} ===\")\n",
    "    print(f\"Best model path  : {best_model_filename}\")\n",
    "    print(f\"Accuracy         : {accuracy:.4f}\")\n",
    "    print(f\"Macro Precision  : {macro_precision:.4f}\")\n",
    "    print(f\"Macro Recall     : {macro_recall:.4f}\")\n",
    "    print(f\"Macro F1-score   : {macro_f1:.4f}\\n\")\n",
    "    \n",
    "    # Per-class metrics\n",
    "    per_class_precision = precision_score(all_labels, all_preds, average=None)\n",
    "    per_class_recall    = recall_score(all_labels, all_preds, average=None)\n",
    "    per_class_f1        = f1_score(all_labels, all_preds, average=None)\n",
    "    \n",
    "    print(\"=== Per-Class Metrics ===\")\n",
    "    for i, cls in enumerate(class_names):\n",
    "        print(f\"Class: {cls:15s} | Precision: {per_class_precision[i]:.4f} | \"\n",
    "              f\"Recall: {per_class_recall[i]:.4f} | F1-score: {per_class_f1[i]:.4f}\")\n",
    "    \n",
    "    # Plot Confusion Matrix\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "                xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.title(f\"Confusion Matrix - PlantDoc Test Set\\n({checkpoint_path}, run {run_idx})\")\n",
    "    plt.xlabel(\"Predicted Label\")\n",
    "    plt.ylabel(\"True Label\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "##################################\n",
    "# 5. Loop Over Checkpoints for Classification\n",
    "##################################\n",
    "checkpoint_list = [\n",
    "    \"byol_mim_contrastive_epoch85.pth\"\n",
    "]\n",
    "for i, ckpt in enumerate(checkpoint_list, start=1):\n",
    "    fine_tune_and_evaluate(ckpt, run_idx=i, num_finetune_epochs=45)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241d30ee-ba06-4927-9698-ab61621001c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
